{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import stats\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np  \n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import sys\n",
    "from pyecharts.charts import Bar\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.globals import ThemeType\n",
    "from pyecharts.charts import Bar\n",
    "from pyecharts import options as opts\n",
    "import dataframe_image as dfi\n",
    "from jupyterthemes import get_themes\n",
    "import jupyterthemes as jt\n",
    "from jupyterthemes.stylefx import set_nb_theme\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset with the calculated differences Y[t], ommit the first value because difference is NaN and print the head()\n",
    "\n",
    "# def csv_selection():\n",
    "#     print(\"This tool enables you to analyze time series1 First thing you need to do is select your file\")\n",
    "#     fileinput = str(input(\"Please enter the name of the .csv file you want to view: \"))\n",
    "#     if not \".csv\" in fileinput:\n",
    "#         fileinput += \".csv\"\n",
    "# user_input = str(input(\"Please enter the name of the .csv file you want to view: \")\n",
    "\n",
    "def file(fileinput):\n",
    "    if not \".csv\" in fileinput:\n",
    "        fileinput = \"data/\" + fileinput + \".csv\"\n",
    "    \n",
    "    df = pd.read_csv(fileinput,skiprows=0)\n",
    "    df['difference'] = df.iloc[:,1].diff()\n",
    "    df = df.iloc[1:]\n",
    "    df.columns = ['date', 'X[t]', 'Y[t]']\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df.set_index('date', inplace=True)\n",
    "    return df\n",
    "\n",
    "def prepare_data(file(fileinput)):\n",
    "    distribution = df.reset_index(drop=False).iloc[:,1].values\n",
    "    distribution = distribution[:len(distribution)-31]\n",
    "    dates = df.reset_index(drop=False).iloc[:,0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the Random(p) Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_prob_model(counter, probability):\n",
    "    #From the dataframe these are the load values and the dates columns stored in arrays to be processed\n",
    "    distribution = df.reset_index(drop=False).iloc[:,1].values\n",
    "    distribution = distribution[:len(distribution)-31]\n",
    "    dates = df.reset_index(drop=False).iloc[:,0].values\n",
    "\n",
    "    #Fix a probability\n",
    "    #probability = 0.5\n",
    "    #counter = 100\n",
    "\n",
    "    #Empty lists to store times we stopped, loads at each stop and the minimum values of each run and times\n",
    "    load_list = []\n",
    "    time_list = []\n",
    "    minimums = []\n",
    "    minimums_times = []\n",
    "    \n",
    "    \n",
    "    load_data = []\n",
    "    for i in range(0, len(distribution), counter):\n",
    "        chunked_data = distribution[i:i + counter]\n",
    "        min_value = min(chunked_data)\n",
    "        minimums.append(min_value)\n",
    "        min_index = np.where(chunked_data == min_value)[0][0]\n",
    "        minimums_times.append(min_index)\n",
    "        load_data.append(chunked_data)        \n",
    "\n",
    "    for chunk in load_data:\n",
    "        best = 0\n",
    "        index = 0\n",
    "        #Find the best candidate for the model to stop in the first run by comparing the random generated value with the fixed probability x\n",
    "        #If less STOP and offload, else Keep looking unitl the 100th observation\n",
    "        while index <= len(chunk)-1:\n",
    "            x = random.uniform(0, 1)\n",
    "            if x < probability:\n",
    "                best = index\n",
    "                #print (\"Best candidate found! We offload on \" + str(candidate_time[best]) + \"\\nThe load when we offload is \" + str(candidate[best]))\n",
    "                time_list.append(np.where(chunk == chunk[best])[0][0])\n",
    "                load_list.append(chunk[best])\n",
    "                #print(\"The difference between the Optimal and the Achieved load values is \" + str(candidate[best] - minimumL))\n",
    "                break\n",
    "            elif index == counter-1:\n",
    "                best = index\n",
    "                #print (\"Best candidate found! We offload on \" + str(next_times[-1]) + \"\\nThe load when we offload is \"  + str(next_observations[-1]))\n",
    "                time_list.append(np.where(chunk == chunk[best])[0][0])\n",
    "                load_list.append(chunk[best])\n",
    "                #print(\"The difference between the Optimal and the Achieved load values is \" + str(next_observations[-1] - minimumL))\n",
    "                break\n",
    "            index += 1\n",
    "    \n",
    "    load_differences = np.asarray(load_list) - np.asarray(minimums)\n",
    "    times_differences = np.array(time_list) - np.array(minimums_times)\n",
    "    \n",
    "    return minimums, load_list, load_differences, minimums_times, time_list, np.absolute(times_differences)\n",
    "\n",
    "# random_prob_model(100,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Secretary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secretary_model(counter):\n",
    "    #This is the code for the Secretary Problem\n",
    "\n",
    "    #From the dataframe these are the load values and the dates columns stored in arrays to be processed\n",
    "    distribution = df.reset_index(drop=False).iloc[:,1].values\n",
    "    distribution = distribution[:len(distribution)-31]\n",
    "    dates = df.reset_index(drop=False).iloc[:,0].values\n",
    "\n",
    "    #Empty lists to store times we stopped, loads at each stop and the minimum values of each run\n",
    "    time_list = []\n",
    "    load_list = []\n",
    "    minimums = []\n",
    "    minimums_times = []\n",
    "    \n",
    "    load_data = []\n",
    "    for i in range(0, len(distribution), counter):\n",
    "        chunked_data = distribution[i:i + counter]\n",
    "        min_value = min(chunked_data)\n",
    "        minimums.append(min_value)\n",
    "        min_index = np.where(chunked_data == min_value)[0][0]\n",
    "        minimums_times.append(min_index)\n",
    "        load_data.append(chunked_data)\n",
    "    \n",
    "    for chunk in load_data:\n",
    "        samplesize = round(len(chunk) * math.exp(-1))\n",
    "        sample = chunk[ : samplesize]\n",
    "\n",
    "        #Compute the benchmark_secretary of the sample (minimum values of the sample)\n",
    "        benchmark = min(sample)\n",
    "\n",
    "        best = 0\n",
    "        index = samplesize\n",
    "\n",
    "        #Find the best_secretary candidate_secretary for the model to stop in the first run by comparing all next values with the benchmark_secretary value\n",
    "        while index <= len(chunk)-1:\n",
    "            if chunk[index] <= benchmark:\n",
    "                best = index\n",
    "                break\n",
    "            index += 1\n",
    "\n",
    "        #Once we observe the first that is less than the benchmark_secretary value STOP there and offload. Store the value\n",
    "        if(chunk[best] <= benchmark):\n",
    "            time_list.append(np.where(chunk == chunk[best])[0][0])\n",
    "            load_list.append(chunk[best])\n",
    "\n",
    "        #If we dont then go to the end of the 100 observations, Stop there and offload\n",
    "        elif index == counter:\n",
    "            best = index\n",
    "            time_list.append(np.where(chunk == chunk[best-1])[0][0])\n",
    "            load_list.append(chunk[best-1])\n",
    "\n",
    "    load_differences = np.asarray(load_list) - np.asarray(minimums)\n",
    "    times_differences = np.array(time_list) - np.array(minimums_times)\n",
    "    time_delays = [x - 37 for x in time_list]\n",
    "    \n",
    "    return minimums, load_list, load_differences, minimums_times, time_list, np.absolute(times_differences)\n",
    "    \n",
    "#secretary_model(100)[3]\n",
    "#secretary_model(100)[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the House Selling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Dataset\n",
    "# A = [[2,6,7,10,4,7,4,8,9,3], [8,5,3,9,1,7,9,10,4,3]] \n",
    "def house_selling_model(counter, r):\n",
    "    distribution = df.reset_index(drop=False).iloc[:,1].values\n",
    "    distribution = distribution[:len(distribution)-31]\n",
    "    dates = df.reset_index(drop=False).iloc[:,0].values\n",
    "\n",
    "    N = counter\n",
    "\n",
    "    #Empty lists to store times we stopped, loads at each stop and the minimum values of each run and times\n",
    "    scaled_list = []\n",
    "    load_list = []\n",
    "    time_list = []\n",
    "    minimums = []\n",
    "    minimums_times = []\n",
    "\n",
    "    A = []\n",
    "    for i in range(0, len(distribution), counter):\n",
    "        chunked_data = distribution[i:i + counter]\n",
    "        min_value = min(chunked_data)\n",
    "        minimums.append(min_value)\n",
    "        min_index = np.where(chunked_data == min_value)[0][0]\n",
    "        minimums_times.append(min_index)\n",
    "        A.append(chunked_data)\n",
    "\n",
    "    # Scale the availability values\n",
    "    for each in A:\n",
    "        scaled_availability = np.full(shape=len(each), fill_value=0, dtype=np.float)\n",
    "        for k in range(1,len(each)):\n",
    "            scaled_availability[k] = (max(each) - each[k])/(max(each) - min(each))\n",
    "        scaled_list.append(scaled_availability)\n",
    "        \n",
    "\n",
    "    a = np.full(shape=counter, fill_value=0, dtype=np.float)\n",
    "    for i in range(N-2,-1,-1):\n",
    "        a[i] = (1/(1+r))*((1+(a[i+1])**2)/2)\n",
    "\n",
    "\n",
    "    c = 0\n",
    "    for each_list in scaled_list:\n",
    "        for i in range(0,len(each_list)+1):\n",
    "            if each_list[i] >= a[i]:\n",
    "                load_list.append(A[c][i])\n",
    "                time_list.append(i)\n",
    "                break\n",
    "        c += 1\n",
    "        \n",
    "    load_differences = np.asarray(load_list) - np.asarray(minimums)\n",
    "    times_differences = np.array(time_list) - np.array(minimums_times)\n",
    "    \n",
    "    return minimums, load_list, load_differences, minimums_times, time_list, np.absolute(times_differences)\n",
    "\n",
    "#house_selling_model(100, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNS AND VALUES SIMULATIONS FOR MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate the random prob model by defining the rpb to be executed\n",
    "#Define chunk_func as rpb_200[0-4] and chunks N\n",
    "def randomP_simulation_run(chunk_func, N):\n",
    "    n_groups = len(chunk_func[0])\n",
    "\n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(1, 1,figsize=(150,30)) # plt.subplots()\n",
    "    index = np.arange(n_groups)\n",
    "    #print(index + bar_width)\n",
    "    bar_width = 0.4\n",
    "    opacity = 0.8\n",
    "\n",
    "    #Plot the achieved values of each observed samle\n",
    "    rects2 = plt.bar(index, chunk_func[1], bar_width,alpha=opacity,color='black',label='Achieved')\n",
    "    #Plot the minimum values of each observed sample\n",
    "    rects1 = plt.bar(index + bar_width, chunk_func[0], bar_width,alpha=opacity,color='darkred',label='Optimal')\n",
    "\n",
    "    #Label\n",
    "    plt.xlabel('Stops', fontsize = 50)\n",
    "    plt.ylabel('Load Values', fontsize = 50)\n",
    "    plt.title('Loads by Stop with for N = {} for Random(P) Model'.format(N), fontsize = 75)\n",
    "    plt.xticks(index + bar_width / 2, tuple(range(1,n_groups+1)))\n",
    "    plt.xlim([0-bar_width/2,index.size])\n",
    "    for p in ax.patches:\n",
    "           ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', rotation=90, xytext=(0, 20), textcoords='offset points', fontsize = 15)\n",
    "    plt.legend()\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig('random(p)_loads_{}.jpg'.format(N))\n",
    "#     plt.show()    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1,figsize=(150,30)) # plt.subplots()\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.4\n",
    "    opacity = 0.8\n",
    "    \n",
    "    #Plot the achieved values of each observed samle\n",
    "    rects2 = plt.bar(index, np.absolute(chunk_func[5]), bar_width,alpha=opacity,color='black',label='Achieved')\n",
    "    \n",
    "    #Label\n",
    "    plt.xlabel('Stops', fontsize = 50)\n",
    "    plt.ylabel('Stopping Delay', fontsize = 50)\n",
    "    plt.title('Stopping Delays by Stop with N = {} for Random(P) Model'.format(N), fontsize = 75)\n",
    "    plt.xticks(index, tuple(range(1,n_groups+1)))\n",
    "    plt.xlim([0-bar_width/2,index.size])\n",
    "    for p in ax.patches:\n",
    "           ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 20), textcoords='offset points', fontsize = 15)\n",
    "    plt.legend()\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig('random(p)_times_{}.png'.format(N))\n",
    "#     plt.show()\n",
    "    \n",
    "    #-------------------------------------------------------#\n",
    "\n",
    "    #Display the dataframe\n",
    "    runs_data = {'Run':  list(range(1,len(chunk_func[0])+1)),'Optimal': chunk_func[0],'Load when Offloading': chunk_func[1],\n",
    "                 'Load Difference': chunk_func[2],}\n",
    "\n",
    "    runs_frame = pd.DataFrame(runs_data, columns = ['Run','Optimal','Load when Offloading', 'Load Difference'])\n",
    "    runs_frame.index += 1\n",
    "\n",
    "    display(runs_frame)\n",
    "\n",
    "#Simulate the random prob model by defining the rpb to be executed\n",
    "#Define secretary_model as 200\n",
    "def secretary_simulation_run(chunks):\n",
    "    # data to plot\n",
    "    n_groups_secretary = len(secretary_model(chunks)[0])\n",
    "\n",
    "    # create plot for loads\n",
    "    fig, ax = plt.subplots(1, 1,figsize=(30,30)) # plt.subplots()\n",
    "    index = np.arange(n_groups_secretary)\n",
    "    bar_width = 0.4\n",
    "    opacity = 0.8\n",
    "    \n",
    "    #Plot the achieved values of each observed samle\n",
    "    rects2 = plt.bar(index, secretary_model(chunks)[1], bar_width,alpha=opacity,color='black',label='Achieved')\n",
    "    #Plot the minimum values of each observed sample\n",
    "    rects1 = plt.bar(index + bar_width, secretary_model(chunks)[0], bar_width, alpha=opacity,color='darkred',label='Optimal')\n",
    "    \n",
    "    #Label\n",
    "    plt.xlabel('Stops', fontsize = 15)\n",
    "    plt.ylabel('Load Values', fontsize = 15)\n",
    "    plt.title('Loads by Stop with N = {} for Secretary Model'.format(chunks), fontsize = 25)\n",
    "    plt.xticks(index + bar_width / 2, tuple(range(1,n_groups_secretary+1)))\n",
    "    plt.xlim([0-bar_width/2,index.size])\n",
    "    for p in ax.patches:\n",
    "            ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', rotation=90, xytext=(0, 20), textcoords='offset points', fontsize = 15)\n",
    "    plt.legend()\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig('secretary_loads_{}.png'.format(chunks))\n",
    "#     plt.show()\n",
    "    \n",
    "    #--------------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1,figsize=(30,30)) # plt.subplots()\n",
    "    index = np.arange(n_groups_secretary)\n",
    "    bar_width = 0.4\n",
    "    opacity = 0.8\n",
    "    \n",
    "    #Plot the achieved values of each observed samle\n",
    "    rects2 = plt.bar(index, secretary_model(chunks)[5], bar_width,alpha=opacity,color='black',label='Achieved')\n",
    "    \n",
    "    #Label\n",
    "    plt.xlabel('Stops', fontsize = 15)\n",
    "    plt.ylabel('Stopping Delay', fontsize = 15)\n",
    "    plt.title('Stopping Delays by Stop with N = {} for Secretary Model'.format(chunks), fontsize = 25)\n",
    "    plt.xticks(index, tuple(range(1,n_groups_secretary+1)))\n",
    "    plt.xlim([0-bar_width/2,index.size])\n",
    "    for p in ax.patches:\n",
    "            ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', xytext=(0, 20), textcoords='offset points', fontsize = 15)\n",
    "    plt.legend()\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig('secretary_times_{}.png'.format(chunks))\n",
    "#     plt.show()\n",
    "    \n",
    "    #Display the dataframe\n",
    "    runs_data = {'Run':  list(range(1,len(secretary_model(chunks)[0])+1)),'Optimal': secretary_model(chunks)[0],'Load when Offloading': secretary_model(chunks)[1],\n",
    "                 'Load Difference': secretary_model(chunks)[2],}\n",
    "\n",
    "    runs_frame = pd.DataFrame(runs_data, columns = ['Run','Optimal','Load when Offloading', 'Load Difference'])\n",
    "    runs_frame.index += 1\n",
    "\n",
    "    display(runs_frame)\n",
    "\n",
    "def house_selling_simulation_run(chunks, r):\n",
    "    n_groups_house = len(house_selling_model(chunks, r)[0])\n",
    "\n",
    "    # create plot for loads\n",
    "    fig, ax = plt.subplots(1, 1,figsize=(30,30)) # plt.subplots()\n",
    "    index = np.arange(n_groups_house)\n",
    "    bar_width = 0.4\n",
    "    opacity = 0.8\n",
    "    \n",
    "    #Plot the achieved values of each observed samle\n",
    "    rects2 = plt.bar(index, house_selling_model(chunks, r)[1], bar_width,alpha=opacity,color='black',label='Achieved')\n",
    "    #Plot the minimum values of each observed sample\n",
    "    rects1 = plt.bar(index + bar_width, house_selling_model(chunks, r)[0], bar_width, alpha=opacity,color='darkred',label='Optimal')\n",
    "    \n",
    "    #Label\n",
    "    plt.xlabel('Stops', fontsize = 15)\n",
    "    plt.ylabel('Load Values', fontsize = 15)\n",
    "    plt.title('Loads by Stop with N = {} for House Selling Model'.format(chunks), fontsize = 25)\n",
    "    plt.xticks(index + bar_width / 2, tuple(range(1,n_groups_house+1)))\n",
    "    plt.xlim([0-bar_width/2,index.size])\n",
    "    for p in ax.patches:\n",
    "            ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', rotation=90, xytext=(0, 20), textcoords='offset points', fontsize = 15)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig('hs_loads_{}.png'.format(chunks))\n",
    "#     plt.show()\n",
    "    \n",
    "    #--------------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1,figsize=(30,30)) # plt.subplots()\n",
    "    index = np.arange(n_groups_house)\n",
    "    bar_width = 0.4\n",
    "    opacity = 0.8\n",
    "    \n",
    "    #Plot the achieved values of each observed samle\n",
    "    rects2 = plt.bar(index, house_selling_model(chunks, r)[5], bar_width,alpha=opacity,color='black',label='Achieved')\n",
    "    \n",
    "    #Label\n",
    "    plt.xlabel('Stops', fontsize = 15)\n",
    "    plt.ylabel('Stopping Delay', fontsize = 15)\n",
    "    plt.title('Stopping Delays by Stop with N = {} for House Selling Model'.format(chunks), fontsize = 25)\n",
    "    plt.xticks(index, tuple(range(1,n_groups_house+1)))\n",
    "    plt.xlim([0-bar_width/2,index.size])\n",
    "    for p in ax.patches:\n",
    "            ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', xytext=(0, 20), textcoords='offset points', fontsize = 15)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig('hs_times_{}.png'.format(chunks))\n",
    "#     plt.show()\n",
    "    \n",
    "    #Display the dataframe\n",
    "    runs_data = {'Run':  list(range(1,len(house_selling_model(chunks, r)[0])+1)),'Optimal': house_selling_model(chunks, r)[0],'Load when Offloading': house_selling_model(chunks, r)[1],\n",
    "                 'Load Difference': house_selling_model(chunks, r)[2],}\n",
    "\n",
    "    runs_frame = pd.DataFrame(runs_data, columns = ['Run','Optimal','Load when Offloading', 'Load Difference'])\n",
    "    runs_frame.index += 1\n",
    "\n",
    "    display(runs_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM AND SECRETARY MODELS Vs OPTIMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the different models (random(P) for different probabilities and seecretary model) to compare with the optimal for each model\n",
    "\n",
    "#Set the rpb_model(eg. rpb_200) and the secretary model(eg. secretary model(200))\n",
    "def avg_loads_by_stop(rpb_model, secretary_model, house_selling_model):\n",
    "    fig, ax = plt.subplots(1, 1,figsize=(15,15)) \n",
    "    bar_width = 0.4\n",
    "    opacity = 0.8\n",
    "    \n",
    "    optimal_means = [np.mean(rpb_model[0][0]),np.mean(rpb_model[1][0]),np.mean(rpb_model[2][0]),np.mean(rpb_model[3][0]),\n",
    "                              np.mean(rpb_model[4][0]), np.mean(secretary_model[0]), np.mean(house_selling_model[0])]\n",
    "    \n",
    "    achieved_means = [np.mean(rpb_model[0][1]),np.mean(rpb_model[1][1]),np.mean(rpb_model[2][1]),np.mean(rpb_model[3][1]),\n",
    "                             np.mean(rpb_model[4][1]),np.mean(secretary_model[1]), np.mean(house_selling_model[1])]\n",
    "    \n",
    "    all_means = np.array([np.mean(rpb_model[0][0]), np.mean(rpb_model[0][1]),np.mean(rpb_model[1][1]),np.mean(rpb_model[2][1]),np.mean(rpb_model[3][1]),\n",
    "                             np.mean(rpb_model[4][1]),np.mean(secretary_model[1]), np.mean(house_selling_model[1])])\n",
    "    \n",
    "    comparison = all_means - all_means[0][None]\n",
    "    comp = list(comparison)\n",
    "    comp.pop(0)\n",
    "\n",
    "    #Plot the achieved values of each observed samle\n",
    "    rects2 = plt.bar(np.arange(8) + bar_width, all_means, bar_width,alpha=opacity,color = '#99ccff',label='Means')\n",
    "    rects2[0].set_color('g')\n",
    "\n",
    "    #Label\n",
    "    x_ticks_labels = ['Optimal', 'Random(P = 0.05)','Random(P = 0.1)','Random(P = 0.2)','Random(P = 0.3)','Random(P = 0.5)', 'Secretary', 'House Selling']\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Load Values')\n",
    "    plt.title('Avg Loads by Stop for each Model with N = 200')\n",
    "    plt.xticks(np.arange(8) + bar_width, ('Optimal','Random(P = 0.05)','Random(P = 0.1)','Random(P = 0.2)','Random(P = 0.3)','Random(P = 0.5)', 'Secretary', 'House Selling'), rotation = 45)\n",
    "    for p in ax.patches:\n",
    "            ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', rotation=0, xytext=(0, 20), textcoords='offset points')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig('Averages for chosen N.png')\n",
    "\n",
    "\n",
    "    #plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "    #Display the dataframe\n",
    "    runs_data = {'Model':  ['Random(P = 0.05)','Random(P = 0.1)','Random(P = 0.2)','Random(P = 0.3)','Random(P = 0.5)', 'Secretary', 'House Selling'],\n",
    "                 'Optimal Means': optimal_means,\n",
    "                 'Offloading Means': achieved_means,\n",
    "                 'Mean Load Difference': comp} #np.array(achieved_means) - np.array(optimal_means)}\n",
    "\n",
    "    runs_frame = pd.DataFrame(runs_data, columns = ['Model','Optimal Means',\n",
    "                                                    'Offloading Means',\n",
    "                                                    'Mean Load Difference'])\n",
    "    runs_frame.index += 1\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    ax1 = plt.subplot(111)\n",
    "    ret = ax1.bar(runs_frame['Model'], runs_frame['Mean Load Difference'], color = '#99ccff')\n",
    "    ret[np.where(runs_frame['Mean Load Difference'] == runs_frame['Mean Load Difference'].min())[0][0]].set_color('#404040')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Load Difference')\n",
    "    plt.title('Load Mean Differences for N = ')\n",
    "    for p in ax1.patches:\n",
    "            ax1.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', rotation=0, xytext=(0, 20), textcoords='offset points')\n",
    "    \n",
    "    \n",
    "    plt.savefig('Averages for chose N.png')\n",
    "    plt.show\n",
    "        \n",
    "    display(runs_frame)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#These are the Random(P) probability models\n",
    "#ALL COMBINATIONS OF CHUNKS AND PROBABILITIES\n",
    "#RUN THESE BEFORE PROCEEDING TO ANALYSIS\n",
    "# rpb_20 = [random_prob_model(20, 0.05),\n",
    "# random_prob_model(20, 0.1),\n",
    "# random_prob_model(20, 0.2),\n",
    "# random_prob_model(20, 0.3),\n",
    "# random_prob_model(20, 0.5)]\n",
    "\n",
    "# rpb_50 = [random_prob_model(50, 0.05),\n",
    "# random_prob_model(50, 0.1),\n",
    "# random_prob_model(50, 0.2),\n",
    "# random_prob_model(50, 0.3),\n",
    "# random_prob_model(50, 0.5)]\n",
    "\n",
    "# rpb_80 = [random_prob_model(80, 0.05),\n",
    "# random_prob_model(80, 0.1),\n",
    "# random_prob_model(80, 0.2),\n",
    "# random_prob_model(80, 0.3),\n",
    "# random_prob_model(80, 0.5)]\n",
    "\n",
    "# rpb_100 = [random_prob_model(100, 0.05),\n",
    "# random_prob_model(100, 0.1),\n",
    "# random_prob_model(100, 0.2),\n",
    "# random_prob_model(100, 0.3),\n",
    "# random_prob_model(100, 0.5)]\n",
    "\n",
    "# rpb_150 = [random_prob_model(150, 0.05),\n",
    "# random_prob_model(150, 0.1),\n",
    "# random_prob_model(150, 0.2),\n",
    "# random_prob_model(150, 0.3),\n",
    "# random_prob_model(150, 0.5)]\n",
    "\n",
    "# rpb_200 = [random_prob_model(200, 0.05),\n",
    "# random_prob_model(200, 0.1),\n",
    "# random_prob_model(200, 0.2),\n",
    "# random_prob_model(200, 0.3),\n",
    "# random_prob_model(200, 0.5)]\n",
    "\n",
    "\n",
    "#EXAMPLES, run the models by changing the chunk number (eg. rpb_200) and the square bracket value for the Probability\n",
    "\n",
    "#Probabilities\n",
    "# 0 = 0.05\n",
    "# 1 = 0.1\n",
    "# 2 = 0.2\n",
    "# 3 = 0.3\n",
    "# 4 = 0.5\n",
    "\n",
    "#Chunks N\n",
    "# 20,50,80,100,150,200\n",
    "\n",
    "#For the House Selling model define chunks and the factor r (eg r = 0.1)\n",
    "\n",
    "\n",
    "# #MODELS\n",
    "# randomP_simulation_run(rpb_100[0],100)\n",
    "# secretary_simulation_run(100)\n",
    "# house_selling_simulation_run(100, 0)\n",
    "# # avg_loads_by_stop(rpb_50, secretary_model(100), house_selling_model(100, 0.2))\n",
    "# # avg_loads_by_stop(rpb_80, secretary_model(100), house_selling_model(100, 0.2))\n",
    "# # avg_loads_by_stop(rpb_100, secretary_model(100), house_selling_model(100, 0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #MODELS\n",
    "# randomP_simulation_run(rpb_100[0],100)\n",
    "# secretary_simulation_run(100)\n",
    "# house_selling_simulation_run(100, 0)\n",
    "# # avg_loads_by_stop(rpb_50, secretary_model(100), house_selling_model(100, 0.2))\n",
    "# # avg_loads_by_stop(rpb_80, secretary_model(100), house_selling_model(100, 0.2))\n",
    "# # avg_loads_by_stop(rpb_100, secretary_model(100), house_selling_model(100, 0.2))\n",
    "# avg_loads_by_stop(rpb_50, secretary_model(50), house_selling_model(50, 0.052))\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    fileinput = str(input(\"Please enter the name of the .csv file you want to view: \"))\n",
    "    \n",
    "    print(file(fileinput))\n",
    "    \n",
    "    #Generate the dataset for the Random(P) Model\n",
    "    rpb_20 = [random_prob_model(20, 0.05),random_prob_model(20, 0.1),random_prob_model(20, 0.2),random_prob_model(20, 0.3),random_prob_model(20, 0.5)]\n",
    "    rpb_50 = [random_prob_model(50, 0.05),random_prob_model(50, 0.1),random_prob_model(50, 0.2),random_prob_model(50, 0.3),random_prob_model(50, 0.5)]\n",
    "    rpb_80 = [random_prob_model(80, 0.05),random_prob_model(80, 0.1),random_prob_model(80, 0.2),random_prob_model(80, 0.3),random_prob_model(80, 0.5)]\n",
    "    rpb_100 = [random_prob_model(100, 0.05),random_prob_model(100, 0.1),random_prob_model(100, 0.2),random_prob_model(100, 0.3),random_prob_model(100, 0.5)]\n",
    "    rpb_150 = [random_prob_model(150, 0.05),random_prob_model(150, 0.1),random_prob_model(150, 0.2),random_prob_model(150, 0.3),random_prob_model(150, 0.5)]\n",
    "    rpb_200 = [random_prob_model(200, 0.05),random_prob_model(200, 0.1),random_prob_model(200, 0.2),random_prob_model(200, 0.3),random_prob_model(200, 0.5)]\n",
    "        \n",
    "    mode_selection = str(input(\"\\nWelcome! This tool enables you to analyze time-series data with OST models.\\n\\n 1 = Individual Models\\n 2 = All Models Average\\n\\nPlease select if you want to individually run models or compare all models' average: \"))\n",
    "    \n",
    "    if mode_selection == '1':\n",
    "    \n",
    "        selection = str(input(\"You can choose from:\\n 1 = Random(P) Model\\n 2 = Secretary Model\\n 3 = House Selling Model\\n\\nEnter your selection: \"))\n",
    "\n",
    "        while(selection != '!'):\n",
    "\n",
    "            if selection == '1':\n",
    "                chunk_selection = int(input(\"Please enter the number of chunks you want to analyze. You can choose from the set [20,50,80,100,150,200]: \"))\n",
    "                if chunk_selection == 20:\n",
    "                    probability_selection = int(input(\"Please enter the number of chunks you want to analyze.\\n\\nYou can choose from:\\n 0 = 0.05\\n 1 = 0.1\\n 2 = 0.2\\n 3 = 0.3\\n 4 = 0.5\\n\\nEnter your selection: \"))\n",
    "                    randomP_simulation_run(rpb_20[probability_selection], chunk_selection)\n",
    "                if chunk_selection == 50:\n",
    "                    probability_selection = int(input(\"Please enter the number of chunks you want to analyze.\\n\\nYou can choose from:\\n 0 = 0.05\\n 1 = 0.1\\n 2 = 0.2\\n 3 = 0.3\\n 4 = 0.5\\n\\nEnter your selection: \"))\n",
    "                    randomP_simulation_run(rpb_50[probability_selection], chunk_selection)\n",
    "                if chunk_selection == 80:\n",
    "                    probability_selection = int(input(\"Please enter the number of chunks you want to analyze.\\n\\nYou can choose from:\\n 0 = 0.05\\n 1 = 0.1\\n 2 = 0.2\\n 3 = 0.3\\n 4 = 0.5\\n\\nEnter your selection: \"))\n",
    "                    randomP_simulation_run(rpb_80[probability_selection], chunk_selection)\n",
    "                if chunk_selection == 100:\n",
    "                    probability_selection = int(input(\"Please enter the number of chunks you want to analyze.\\n\\nYou can choose from:\\n 0 = 0.05\\n 1 = 0.1\\n 2 = 0.2\\n 3 = 0.3\\n 4 = 0.5\\n\\nEnter your selection: \"))\n",
    "                    randomP_simulation_run(rpb_100[probability_selection], chunk_selection)\n",
    "                if chunk_selection == 150:\n",
    "                    probability_selection = int(input(\"Please enter the number of chunks you want to analyze.\\n\\nYou can choose from:\\n 0 = 0.05\\n 1 = 0.1\\n 2 = 0.2\\n 3 = 0.3\\n 4 = 0.5\\n\\nEnter your selection: \"))\n",
    "                    randomP_simulation_run(rpb_150[probability_selection], chunk_selection)\n",
    "                if chunk_selection == 200:\n",
    "                    probability_selection = int(input(\"Please enter the number of chunks you want to analyze.\\n\\nYou can choose from:\\n 0 = 0.05\\n 1 = 0.1\\n 2 = 0.2\\n 3 = 0.3\\n 4 = 0.5\\n\\nEnter your selectio: \"))\n",
    "                    randomP_simulation_run(rpb_200[probability_selection], chunk_selection)\n",
    "            elif selection == '2':\n",
    "                chunk_selection = int(input(\"Please enter the number of chunks you want to analyze: \"))\n",
    "                secretary_simulation_run(chunk_selection)\n",
    "            elif selection == '3':\n",
    "                chunk_selection = int(input(\"Please enter the number of chunks you want to analyze: \"))\n",
    "                r_factor = float(input(\"Please enter the R factor you want to use: \"))\n",
    "                house_selling_simulation_run(chunk_selection,r_factor)\n",
    "            else:\n",
    "                print(\"Error! Please enter a valid selection!\")\n",
    "\n",
    "            print(\"\\nYour result figures have been saved. You can view them in the source folder!\\n\\n\")\n",
    "            selection = str(input(\"\\nPlease enter which simulation you want to run or enter '!' + Enter to quit: \"))       \n",
    "            \n",
    "    elif mode_selection == '2':\n",
    "        \n",
    "        retry = y\n",
    "        \n",
    "        while(retry != '!'):\n",
    "            \n",
    "            chunk_selection = int(input(\"Please enter the number of chunks you want to analyze: \"))\n",
    "            \n",
    "            if chunk_selection == 20:\n",
    "                r_factor = float(input(\"Please enter the R factor you want to use: \"))\n",
    "                avg_loads_by_stop(rpb_20, secretary_model(chunk_selection), house_selling_model(chunk_selection, r_factor))\n",
    "            if chunk_selection == 50:\n",
    "                r_factor = float(input(\"Please enter the R factor you want to use: \"))\n",
    "                avg_loads_by_stop(rpb_50, secretary_model(chunk_selection), house_selling_model(chunk_selection, r_factor))\n",
    "            if chunk_selection == 80:\n",
    "                r_factor = float(input(\"Please enter the R factor you want to use: \"))\n",
    "                avg_loads_by_stop(rpb_80, secretary_model(chunk_selection), house_selling_model(chunk_selection, r_factor))\n",
    "            if chunk_selection == 100:\n",
    "                r_factor = float(input(\"Please enter the R factor you want to use: \"))\n",
    "                avg_loads_by_stop(rpb_100, secretary_model(chunk_selection), house_selling_model(chunk_selection, r_factor))\n",
    "            if chunk_selection == 150:\n",
    "                r_factor = float(input(\"Please enter the R factor you want to use: \"))\n",
    "                avg_loads_by_stop(rpb_150, secretary_model(chunk_selection), house_selling_model(chunk_selection, r_factor))\n",
    "            if chunk_selection == 200:\n",
    "                r_factor = float(input(\"Please enter the R factor you want to use: \"))\n",
    "                avg_loads_by_stop(rpb_200, secretary_model(chunk_selection), house_selling_model(chunk_selection, r_factor))\n",
    "                \n",
    "            retry = str(input(\"Do you want to repeat? \"))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-7fdf6dd1581e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m      \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-73-0f5ea4c60171>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mfileinput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please enter the name of the .csv file you want to view: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileinput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
